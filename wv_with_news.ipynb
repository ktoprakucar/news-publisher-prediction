{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/toprak.ucar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import datetime\n",
    "import re\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "from h2o.estimators.word2vec import H2OWord2vecEstimator\n",
    "from h2o.estimators import H2OGradientBoostingEstimator\n",
    "from h2o.estimators import H2ORandomForestEstimator\n",
    "import h2o\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['articles1.csv', 'articles3.csv', 'articles2.csv']\n"
     ]
    }
   ],
   "source": [
    "csv_files = [pos_csv for pos_csv in os.listdir(\"data/\") if pos_csv.endswith('.csv')]\n",
    "print(csv_files)\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for file in csv_files:\n",
    "    df = df.append(pd.read_csv(\"data/\" + file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'title', 'publication', 'author', 'date', 'year',\n",
       "       'month', 'url', 'content'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['author', 'date', 'year', 'month', 'url'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['publication'] = df['publication'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].str.replace('[^a-zA-Zğüşçö]', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>atlantic</th>\n",
       "      <td>7179</td>\n",
       "      <td>7179</td>\n",
       "      <td>7179</td>\n",
       "      <td>7179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breitbart</th>\n",
       "      <td>23781</td>\n",
       "      <td>23781</td>\n",
       "      <td>23781</td>\n",
       "      <td>23781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business insider</th>\n",
       "      <td>6757</td>\n",
       "      <td>6757</td>\n",
       "      <td>6757</td>\n",
       "      <td>6757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buzzfeed news</th>\n",
       "      <td>4854</td>\n",
       "      <td>4854</td>\n",
       "      <td>4854</td>\n",
       "      <td>4854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn</th>\n",
       "      <td>11488</td>\n",
       "      <td>11488</td>\n",
       "      <td>11488</td>\n",
       "      <td>11488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox news</th>\n",
       "      <td>4354</td>\n",
       "      <td>4354</td>\n",
       "      <td>4354</td>\n",
       "      <td>4354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guardian</th>\n",
       "      <td>8681</td>\n",
       "      <td>8681</td>\n",
       "      <td>8681</td>\n",
       "      <td>8681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>national review</th>\n",
       "      <td>6203</td>\n",
       "      <td>6203</td>\n",
       "      <td>6203</td>\n",
       "      <td>6203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york post</th>\n",
       "      <td>17493</td>\n",
       "      <td>17493</td>\n",
       "      <td>17493</td>\n",
       "      <td>17493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york times</th>\n",
       "      <td>7803</td>\n",
       "      <td>7803</td>\n",
       "      <td>7803</td>\n",
       "      <td>7803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npr</th>\n",
       "      <td>11992</td>\n",
       "      <td>11992</td>\n",
       "      <td>11992</td>\n",
       "      <td>11992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reuters</th>\n",
       "      <td>10710</td>\n",
       "      <td>10710</td>\n",
       "      <td>10709</td>\n",
       "      <td>10710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talking points memo</th>\n",
       "      <td>5214</td>\n",
       "      <td>5214</td>\n",
       "      <td>5213</td>\n",
       "      <td>5214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vox</th>\n",
       "      <td>4947</td>\n",
       "      <td>4947</td>\n",
       "      <td>4947</td>\n",
       "      <td>4947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>washington post</th>\n",
       "      <td>11114</td>\n",
       "      <td>11114</td>\n",
       "      <td>11114</td>\n",
       "      <td>11114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Unnamed: 0     id  title  content\n",
       "publication                                           \n",
       "atlantic                   7179   7179   7179     7179\n",
       "breitbart                 23781  23781  23781    23781\n",
       "business insider           6757   6757   6757     6757\n",
       "buzzfeed news              4854   4854   4854     4854\n",
       "cnn                       11488  11488  11488    11488\n",
       "fox news                   4354   4354   4354     4354\n",
       "guardian                   8681   8681   8681     8681\n",
       "national review            6203   6203   6203     6203\n",
       "new york post             17493  17493  17493    17493\n",
       "new york times             7803   7803   7803     7803\n",
       "npr                       11992  11992  11992    11992\n",
       "reuters                   10710  10710  10709    10710\n",
       "talking points memo        5214   5214   5213     5214\n",
       "vox                        4947   4947   4947     4947\n",
       "washington post           11114  11114  11114    11114"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['publication']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142570"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"isBreitbart\"] = np.where(df['publication'] == 'breitbart', \"1\", \"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for count in range (len(df)):\n",
    "    if (type(df.iloc[count]['content']) != float):\n",
    "        words.append(df.iloc[count]['content'].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(words, windoaw=50, \n",
    "                                       size= 1000, iter=5, \n",
    "                                       min_count=3, workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/toprak.ucar/anaconda3/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('bosporus', 0.6041005849838257),\n",
       " ('reina', 0.5746868848800659),\n",
       " ('bosphorus', 0.573968231678009),\n",
       " ('ataturk', 0.5490278005599976),\n",
       " ('mehmet', 0.5461439490318298),\n",
       " ('ankara', 0.5452790260314941),\n",
       " ('hurriyet', 0.5435633659362793),\n",
       " ('turkish', 0.5372835993766785),\n",
       " ('pamuk', 0.5340129137039185),\n",
       " ('istiklal', 0.5253186225891113)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word(\"istanbul\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/toprak.ucar/anaconda3/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('neymar', 0.6838817596435547),\n",
       " ('ronaldo', 0.6767688989639282),\n",
       " ('barcelona', 0.6438531279563904),\n",
       " ('goalkeeper', 0.6131119728088379),\n",
       " ('cristiano', 0.6047729253768921),\n",
       " ('sevilla', 0.5975548028945923),\n",
       " ('barca', 0.5932743549346924),\n",
       " ('griezmann', 0.5716344118118286),\n",
       " ('piqu', 0.5712944269180298),\n",
       " ('striker', 0.5618128776550293)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word(\"messi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/toprak.ucar/anaconda3/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('kemal', 0.5918941497802734),\n",
       " ('atatürk', 0.5512984991073608),\n",
       " ('istanbul', 0.5490278005599976),\n",
       " ('coups', 0.49630677700042725),\n",
       " ('ottoman', 0.4951777160167694),\n",
       " ('akp', 0.48499637842178345),\n",
       " ('erdoğan', 0.4355770945549011),\n",
       " ('mustafa', 0.4154052734375),\n",
       " ('ankara', 0.41123801469802856),\n",
       " ('turkey', 0.41080719232559204)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word(\"ataturk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/toprak.ucar/anaconda3/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ankara', 0.45684361457824707),\n",
       " ('turkish', 0.4347909688949585),\n",
       " ('istanbul', 0.3412559926509857),\n",
       " ('turks', 0.31825536489486694),\n",
       " ('incirlik', 0.2970038950443268),\n",
       " ('lira', 0.2946658432483673),\n",
       " ('ahmet', 0.28686249256134033),\n",
       " ('recep', 0.2867054343223572),\n",
       " ('izmir', 0.28641149401664734),\n",
       " ('erdogan', 0.2806168496608734)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['paris', 'turkey'], negative=['france'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/toprak.ucar/anaconda3/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('turkish', 0.4010379910469055),\n",
       " ('ankara', 0.388433575630188),\n",
       " ('erdoğan', 0.3822430968284607),\n",
       " ('erdogan', 0.3731622099876404),\n",
       " ('yildirim', 0.3409467041492462),\n",
       " ('davutoglu', 0.3317990005016327),\n",
       " ('turks', 0.29959139227867126),\n",
       " ('recep', 0.286358118057251),\n",
       " ('lira', 0.27761685848236084),\n",
       " ('hurriyet', 0.27162522077560425)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['trump', 'turkey'], negative=['america'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/toprak.ucar/anaconda3/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ronaldo', 0.6099832057952881),\n",
       " ('cristiano', 0.5582559704780579),\n",
       " ('atl', 0.5154239535331726),\n",
       " ('atletico', 0.5150270462036133),\n",
       " ('neymar', 0.5147936344146729),\n",
       " ('sevilla', 0.5030616521835327),\n",
       " ('tico', 0.5014896988868713),\n",
       " ('lionel', 0.49445661902427673),\n",
       " ('isco', 0.48357024788856506),\n",
       " ('maradona', 0.47977331280708313)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['messi', 'madrid'], negative=['barcelona'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/toprak.ucar/anaconda3/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('madrid', 0.4317438304424286),\n",
       " ('barcelona', 0.38237810134887695),\n",
       " ('milan', 0.36274564266204834),\n",
       " ('spaniards', 0.33720114827156067),\n",
       " ('bogot', 0.33717870712280273),\n",
       " ('spanish', 0.3279109001159668),\n",
       " ('roberto', 0.324995219707489),\n",
       " ('jos', 0.3247702419757843),\n",
       " ('ignacio', 0.32421284914016724),\n",
       " ('claudio', 0.31243082880973816)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['paris', 'spain'], negative=['france'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(fname_or_handle=\"model/\" + \"model_for_news\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
